{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Vincent Kim\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dac3401f7e517b1cec72732f9437fb58",
     "grade": false,
     "grade_id": "cell-dd54ad0671f620b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Machine Learning in Spark\n",
    "\n",
    "Following the evolution of Spark, there are two ways to do Machine Learning on Spark :\n",
    "\n",
    "* MLlib, or `spark.mllib`, was the first ML library implemented in the core Spark library and runs on RDDs. As of today, the library is in maintenance mode, but as we did for RDDs vs DataFrames, it is important that we cover some aspects of the older library. MLlib is also the only library that supports training models for Spark Streaming. \n",
    "* ML, or `spark.ml` is now the primary ML library on Spark, and runs on DataFrames. Its API is close to those of other mainstream librairies like scikit-learn.\n",
    "\n",
    "We will dive into both APIs in this notebook, using the `titanic.csv` file for classification purposes on the `Survived` column.\n",
    "\n",
    "_I think at this point of your career, you all know what the [Titanic dataset](https://www.kaggle.com/c/titanic/data) is..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92387c8478a08f6cd442a007010a80ea",
     "grade": false,
     "grade_id": "cell-1e94907f4239a99c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName('lecture-lyon2').setMaster('local[*]')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d56e90c8e0a2f67a92b3eaaf5feef3c",
     "grade": false,
     "grade_id": "cell-4374dd3b71e3e1aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.linalg import VectorUDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "527fbbddcd0832714c2618aa70ee0cbd",
     "grade": false,
     "grade_id": "cell-d28fe8378ff439c1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Data preparation\n",
    "\n",
    "Even though MLlib is designed with RDDs and DStreams in focus, for ease of transforming the data we will read the data and convert it to a DataFrame. Afterwards we will build RDDs for training in MLlib, or stay in DataFrame for training in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c8f2873bc0c500cab02f7e7d484a5e76",
     "grade": false,
     "grade_id": "cell-d2682ed444b1c83c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load('../data/titanic.csv')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f6b121e284c520dc982f47aa2a64dab",
     "grade": false,
     "grade_id": "cell-ca71837cedb092f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.3838383838383838</td>\n",
       "      <td>2.308641975308642</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>29.69911764705882</td>\n",
       "      <td>0.5230078563411896</td>\n",
       "      <td>0.38159371492704824</td>\n",
       "      <td>260318.54916792738</td>\n",
       "      <td>32.2042079685746</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>257.3538420152301</td>\n",
       "      <td>0.48659245426485753</td>\n",
       "      <td>0.8360712409770491</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14.526497332334035</td>\n",
       "      <td>1.1027434322934315</td>\n",
       "      <td>0.8060572211299488</td>\n",
       "      <td>471609.26868834975</td>\n",
       "      <td>49.69342859718089</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"</td>\n",
       "      <td>female</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>891</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>WE/P 5735</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary        PassengerId             Survived              Pclass  \\\n",
       "0   count                891                  891                 891   \n",
       "1    mean              446.0   0.3838383838383838   2.308641975308642   \n",
       "2  stddev  257.3538420152301  0.48659245426485753  0.8360712409770491   \n",
       "3     min                  1                    0                   1   \n",
       "4     max                891                    1                   3   \n",
       "\n",
       "                                               Name     Sex  \\\n",
       "0                                               891     891   \n",
       "1                                              None    None   \n",
       "2                                              None    None   \n",
       "3  \"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"  female   \n",
       "4                       van Melkebeke, Mr. Philemon    male   \n",
       "\n",
       "                  Age               SibSp                Parch  \\\n",
       "0                 714                 891                  891   \n",
       "1   29.69911764705882  0.5230078563411896  0.38159371492704824   \n",
       "2  14.526497332334035  1.1027434322934315   0.8060572211299488   \n",
       "3                0.42                   0                    0   \n",
       "4                80.0                   8                    6   \n",
       "\n",
       "               Ticket               Fare Cabin Embarked  \n",
       "0                 891                891   204      889  \n",
       "1  260318.54916792738   32.2042079685746  None     None  \n",
       "2  471609.26868834975  49.69342859718089  None     None  \n",
       "3              110152                0.0   A10        C  \n",
       "4           WE/P 5735           512.3292     T        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "27af6323e3cbecc226fa71cdd931a8ea",
     "grade": false,
     "grade_id": "cell-1ffea3dfd43c7ce6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "From the first summary statistics, we see that the `Age`, `Cabin` and `Embarked` variables can have null values. Also `PassengerId` and `Ticket` look useless for future predictions.\n",
    "\n",
    "# Question\n",
    "  \n",
    "* Drop `Cabin`, `Ticket` and `PassengerId`\n",
    "* Using `.na.fill` function on a DataFrame :\n",
    "    * For `Age`, replace `None` by the mean value for the column. \n",
    "    * For `Embarked` columns, replace `None` by the most frequent value for the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n",
      "S\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass                                               Name  \\\n",
       "0          0       3                            Braund, Mr. Owen Harris   \n",
       "1          1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2          1       3                             Heikkinen, Miss. Laina   \n",
       "3          1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4          0       3                           Allen, Mr. William Henry   \n",
       "5          0       3                                   Moran, Mr. James   \n",
       "6          0       1                            McCarthy, Mr. Timothy J   \n",
       "7          0       3                     Palsson, Master. Gosta Leonard   \n",
       "8          1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9          1       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "10         1       3                    Sandstrom, Miss. Marguerite Rut   \n",
       "11         1       1                           Bonnell, Miss. Elizabeth   \n",
       "12         0       3                     Saundercock, Mr. William Henry   \n",
       "13         0       3                        Andersson, Mr. Anders Johan   \n",
       "14         0       3               Vestrom, Miss. Hulda Amanda Adolfina   \n",
       "15         1       2                   Hewlett, Mrs. (Mary D Kingcome)    \n",
       "16         0       3                               Rice, Master. Eugene   \n",
       "17         1       2                       Williams, Mr. Charles Eugene   \n",
       "18         0       3  Vander Planke, Mrs. Julius (Emelia Maria Vande...   \n",
       "19         1       3                            Masselmani, Mrs. Fatima   \n",
       "\n",
       "       Sex        Age  SibSp  Parch     Fare Embarked  \n",
       "0     male  22.000000      1      0   7.2500        S  \n",
       "1   female  38.000000      1      0  71.2833        C  \n",
       "2   female  26.000000      0      0   7.9250        S  \n",
       "3   female  35.000000      1      0  53.1000        S  \n",
       "4     male  35.000000      0      0   8.0500        S  \n",
       "5     male  29.699118      0      0   8.4583        Q  \n",
       "6     male  54.000000      0      0  51.8625        S  \n",
       "7     male   2.000000      3      1  21.0750        S  \n",
       "8   female  27.000000      0      2  11.1333        S  \n",
       "9   female  14.000000      1      0  30.0708        C  \n",
       "10  female   4.000000      1      1  16.7000        S  \n",
       "11  female  58.000000      0      0  26.5500        S  \n",
       "12    male  20.000000      0      0   8.0500        S  \n",
       "13    male  39.000000      1      5  31.2750        S  \n",
       "14  female  14.000000      0      0   7.8542        S  \n",
       "15  female  55.000000      0      0  16.0000        S  \n",
       "16    male   2.000000      4      1  29.1250        Q  \n",
       "17    male  29.699118      0      0  13.0000        S  \n",
       "18  female  31.000000      1      0  18.0000        S  \n",
       "19  female  29.699118      0      0   7.2250        C  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data\n",
    "columns_to_drop = ['Cabin', 'Ticket', 'PassengerId']\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "#age_df = df.createOrReplaceTempView('psng')\n",
    "#stats = df.describe()\n",
    "#avg_age = spark.sql(\"SELECT Age FROM psng\").show()\n",
    "#avg_age = fn.avg(avg_age)\n",
    "#avg_age = stats.select('Age').show()\n",
    "#avg_age = df.select(avg(df('Age'))).show()\n",
    "#avg_age = df.select(avg($\"Age\")).show()\n",
    "\n",
    "dfp = df.toPandas()\n",
    "#avg_age = dfp.fillna({'Age': df['Age'].mean()})\n",
    "#mode_embark = dfp.fillna({'Embark': df['Embark'].mode()})\n",
    "avg_age = dfp['Age'].mean()\n",
    "print(avg_age)\n",
    "mode_embark = dfp['Embarked'].mode().item()#columns='Embarked', numeric_only=True, dropna=True)\n",
    "print(mode_embark)\n",
    "#avg_age = avg_age.toPandas()\n",
    "#avg_age.head()\n",
    "#dfp.head(20)\n",
    "#print(df['Age'].mean())\n",
    "    \n",
    "df = df.na.fill(avg_age,'Age')\n",
    "df = df.na.fill(mode_embark,'Embarked')\n",
    "df.toPandas().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8981ccf6f3077abd1ad00725d9eb21db",
     "grade": false,
     "grade_id": "cell-852a22563e2c66a2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def replace_na(df):\n",
    "    \"\"\"\n",
    "    Deal with na values, and drop selected columns    \n",
    "    \"\"\"\n",
    "    columns_to_drop = ['Cabin', 'Ticket', 'PassengerId']\n",
    "    df = df.drop(*columns_to_drop)\n",
    "    \n",
    "    #Calculate the statistics\n",
    "    dfp = df.toPandas()\n",
    "    avg_age = dfp['Age'].mean()\n",
    "    mode_embark = dfp['Embarked'].mode().item()\n",
    "    \n",
    "    #Impute the null values\n",
    "    df = df.na.fill(avg_age,'Age')\n",
    "    df = df.na.fill(mode_embark,'Embarked')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "495eb4f93d97689053c64d07cc38cc68",
     "grade": true,
     "grade_id": "cell-9c65ef235a646501",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "3 points\n",
    "\"\"\"\n",
    "result = replace_na(data)\n",
    "assert float(result.describe().toPandas().loc[2]['Age']) - 13 < 0.1\n",
    "assert int(result.describe().toPandas().loc[0]['Embarked']) == 891\n",
    "assert list(result.toPandas().columns.values) == ['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1de211c78b3973a7f5d921c6b072d06a",
     "grade": false,
     "grade_id": "cell-c720dda0d25f41c5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For the following two questions, we will use [Transformers](https://spark.apache.org/docs/2.2.0/ml-pipeline.html#transformers). Technically, a Transformer implements a method `transform()`, which converts one DataFrame into another, generally by appending one or more columns.\n",
    "\n",
    "Example: \n",
    "\n",
    "```python\n",
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "continuousDataFrame = spark.createDataFrame([\n",
    "    (0, 0.1),\n",
    "    (1, 0.8),\n",
    "    (2, 0.2)\n",
    "], [\"id\", \"feature\"])\n",
    "continuousDataFrame.show()\n",
    "\n",
    "binarizer = Binarizer(threshold=0.5, inputCol=\"feature\", outputCol=\"binarized_feature\")\n",
    "binarizedDataFrame = binarizer.transform(continuousDataFrame)\n",
    "print(\"Binarizer output with Threshold = %f\" % binarizer.getThreshold())\n",
    "binarizedDataFrame.show()\n",
    "```\n",
    "\n",
    "Result :\n",
    "\n",
    "```\n",
    "+---+-------+\n",
    "| id|feature|\n",
    "+---+-------+\n",
    "|  0|    0.1|\n",
    "|  1|    0.8|\n",
    "|  2|    0.2|\n",
    "+---+-------+\n",
    "\n",
    "Binarizer output with Threshold = 0.500000\n",
    "+---+-------+-----------------+\n",
    "| id|feature|binarized_feature|\n",
    "+---+-------+-----------------+\n",
    "|  0|    0.1|              0.0|\n",
    "|  1|    0.8|              1.0|\n",
    "|  2|    0.2|              0.0|\n",
    "+---+-------+-----------------+\n",
    "```\n",
    "\n",
    "**Note:** contrary to previous notebooks, I have not imported all of the libraries needed to solve the remaining exercises. When you want to import a library, please import it in the same notebook cell as where you implement your code, otherwise it may impact the automatic grading.\n",
    "\n",
    "# Question\n",
    "\n",
    "Through some regex, the [regex_extract UDF](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF) and [SQLTransformer](https://spark.apache.org/docs/2.2.0/ml-features.html#sqltransformer), get the title of a person from the `Name` column in a `Title` column. Drop the `Name` column afterwards.\n",
    "\n",
    "Example\n",
    "\n",
    "```\n",
    "Braund, Mr. Owen       --> Mr\n",
    "Andria, Doctor. Steve  --> Doctor\n",
    "```\n",
    "\n",
    "_Not a hint: while it is perfectly possible to write a custom UDF to solve this question, it breaks the purpose of using Dataframes for cleaning because UDFs don't benefit from SparkSQL's optimizer engine and have to transform back to Java objects for processing. Spark built-in UDFs don't share this problem._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f63d00d042b0e75410b2cb613b62c616",
     "grade": false,
     "grade_id": "cell-93a47dbea9af3ed9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql.functions import regexp_extract, udf, lit\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "def extract_civility(df):\n",
    "    \"\"\"\n",
    "    Return dataframe dropping Name and replacing with Title\n",
    "    \"\"\"\n",
    "    #df['Title'] = df.select(regexp_extract('Name', '(\\\\s)(\\p{L})(\\.)\\(\\s)', 1).alias('d')).collect()\n",
    "    #df_new = df.withColumn(\"Title\", lit(0))\n",
    "    #df_new['Title'] = df.select(regexp_extract('Name', '\\\\s', 2).alias('Title')).collect()\n",
    "    \n",
    "    df.createOrReplaceTempView(\"__THIS__\") #Not necessary??\n",
    "    #sqlTrans = SQLTransformer(statement=\"SELECT *, regexp_extract(__THIS__.Sex, '(a)(.*)', 1) AS Title FROM __THIS__\")\n",
    "    sqlTrans = SQLTransformer(statement=\"SELECT *, regexp_extract(__THIS__.Name, '(.*, )([[a-zA-Z], ]*)(\\..*)', 2) AS Civility FROM __THIS__\")\n",
    "    #sqlTrans = SQLTransformer(statement=\"SELECT *, regexp_extract('Stengel, Mrs. Charles Emil Henry', '(.*, )(\\w+)(\\..*)', 3) AS Title FROM __THIS__\")\n",
    "    df = sqlTrans.transform(df)\n",
    "    df = df.drop('Name')\n",
    "    return df\n",
    "    #return df\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "result = extract_civility(data)\n",
    "a = result.toPandas()\n",
    "#a[a.Civility == 'Capt'].head(100)\n",
    "#a[a.Civility == 'the Countess'].head(100)\n",
    "#result.toPandas()[['Title']].head(10)\n",
    "#resultCols = result.columns\n",
    "#print(resultCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aaf4120d9637141e40ac9327d2061d52",
     "grade": true,
     "grade_id": "cell-c98d26534a8b160c",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "result = extract_civility(data)\n",
    "resultCols = result.columns\n",
    "assert 'Name' not in resultCols\n",
    "assert 'Civility' in resultCols\n",
    "assert list(result.select('Civility').distinct().toPandas()['Civility'].sort_values().values) == [\n",
    "    'Capt',\n",
    "    'Col',\n",
    "    'Don',\n",
    "    'Dr',\n",
    "    'Jonkheer',\n",
    "    'Lady',\n",
    "    'Major',\n",
    "    'Master',\n",
    "    'Miss',\n",
    "    'Mlle',\n",
    "    'Mme',\n",
    "    'Mr',\n",
    "    'Mrs',\n",
    "    'Ms',\n",
    "    'Rev',\n",
    "    'Sir',\n",
    "    'the Countess'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "840b8c2bfea63a5ef297d22ad9a756a8",
     "grade": false,
     "grade_id": "cell-263e03090b6d1030",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Question \n",
    "\n",
    "[One hot encode](https://spark.apache.org/docs/2.2.0/ml-features.html#onehotencoder) `Sex`, `Civility` and `Embarked` columns into `SexVec`, `CivilityVec` and `EmbarkedVec`. Don't forget to drop the original columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c6fc89f3c0a93f77ce190d1f08ccd505",
     "grade": false,
     "grade_id": "cell-87b6e00fa578a061",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'SexVec', 'CivilityVec', 'EmbarkedVec']\n",
      "12\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+-------------+--------------+-------------+\n",
      "|PassengerId|Survived|Pclass| Age|SibSp|Parch|          Ticket|   Fare|Cabin|       SexVec|   CivilityVec|  EmbarkedVec|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+-------------+--------------+-------------+\n",
      "|          1|       0|     3|22.0|    1|    0|       A/5 21171|   7.25| null|(1,[0],[1.0])|(16,[0],[1.0])|(2,[0],[1.0])|\n",
      "|          2|       1|     1|38.0|    1|    0|        PC 17599|71.2833|  C85|    (1,[],[])|(16,[2],[1.0])|(2,[1],[1.0])|\n",
      "|          3|       1|     3|26.0|    0|    0|STON/O2. 3101282|  7.925| null|    (1,[],[])|(16,[1],[1.0])|(2,[0],[1.0])|\n",
      "|          4|       1|     1|35.0|    1|    0|          113803|   53.1| C123|    (1,[],[])|(16,[2],[1.0])|(2,[0],[1.0])|\n",
      "|          5|       0|     3|35.0|    0|    0|          373450|   8.05| null|(1,[0],[1.0])|(16,[0],[1.0])|(2,[0],[1.0])|\n",
      "|          6|       0|     3|null|    0|    0|          330877| 8.4583| null|(1,[0],[1.0])|(16,[0],[1.0])|    (2,[],[])|\n",
      "|          7|       0|     1|54.0|    0|    0|           17463|51.8625|  E46|(1,[0],[1.0])|(16,[0],[1.0])|(2,[0],[1.0])|\n",
      "|          8|       0|     3| 2.0|    3|    1|          349909| 21.075| null|(1,[0],[1.0])|(16,[3],[1.0])|(2,[0],[1.0])|\n",
      "|          9|       1|     3|27.0|    0|    2|          347742|11.1333| null|    (1,[],[])|(16,[2],[1.0])|(2,[0],[1.0])|\n",
      "|         10|       1|     2|14.0|    1|    0|          237736|30.0708| null|    (1,[],[])|(16,[2],[1.0])|(2,[1],[1.0])|\n",
      "|         11|       1|     3| 4.0|    1|    1|         PP 9549|   16.7|   G6|    (1,[],[])|(16,[1],[1.0])|(2,[0],[1.0])|\n",
      "|         12|       1|     1|58.0|    0|    0|          113783|  26.55| C103|    (1,[],[])|(16,[1],[1.0])|(2,[0],[1.0])|\n",
      "|         13|       0|     3|20.0|    0|    0|       A/5. 2151|   8.05| null|(1,[0],[1.0])|(16,[0],[1.0])|(2,[0],[1.0])|\n",
      "|         14|       0|     3|39.0|    1|    5|          347082| 31.275| null|(1,[0],[1.0])|(16,[0],[1.0])|(2,[0],[1.0])|\n",
      "|         15|       0|     3|14.0|    0|    0|          350406| 7.8542| null|    (1,[],[])|(16,[1],[1.0])|(2,[0],[1.0])|\n",
      "|         16|       1|     2|55.0|    0|    0|          248706|   16.0| null|    (1,[],[])|(16,[2],[1.0])|(2,[0],[1.0])|\n",
      "|         17|       0|     3| 2.0|    4|    1|          382652| 29.125| null|(1,[0],[1.0])|(16,[3],[1.0])|    (2,[],[])|\n",
      "|         18|       1|     2|null|    0|    0|          244373|   13.0| null|(1,[0],[1.0])|(16,[0],[1.0])|(2,[0],[1.0])|\n",
      "|         19|       0|     3|31.0|    1|    0|          345763|   18.0| null|    (1,[],[])|(16,[2],[1.0])|(2,[0],[1.0])|\n",
      "|         20|       1|     3|null|    0|    0|            2649|  7.225| null|    (1,[],[])|(16,[2],[1.0])|(2,[1],[1.0])|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+-------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    \"\"\"\n",
    "    Return dataframe one hot encoding selected columns    \n",
    "    \"\"\"\n",
    "    inputCol = [\"Sex\", \"Civility\", \"Embarked\"]\n",
    "    #outputCol = [\"SexVec\", \"CivilityVec\", \"EmbarkedVec\"]\n",
    "    #stringIndexer = StringIndexer(inputCol=*inputCol, outputCol=*outputCol)\n",
    "    indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in inputCol]\n",
    "    \n",
    "    pipeline = Pipeline(stages=indexers)\n",
    "    df2 = pipeline.fit(df).transform(df)\n",
    "\n",
    "    #df2.show()\n",
    "\n",
    "    #model = stringIndexer.fit(df)\n",
    "    #indexed = model.transform(df)\n",
    "    #indexed.show()\n",
    "    \n",
    "    #df2.show()\n",
    "    #print(inputCol)\n",
    "    df3 = OneHotEncoder(inputCol=\"Sex_index\", outputCol=\"SexVec\").transform(df2)\n",
    "    df3 = OneHotEncoder(inputCol=\"Civility_index\", outputCol=\"CivilityVec\").transform(df3)\n",
    "    df3 = OneHotEncoder(inputCol=\"Embarked_index\", outputCol=\"EmbarkedVec\").transform(df3)\n",
    "    #df3 = [OneHotEncoder(inputCol=*column+\"_index\", outputCol=*column+\"Vec\").transform(df2) for column in inputCol]\n",
    "    \n",
    "    #encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"Vec\") for column in inputCol]\n",
    "    #pipeline2 = Pipeline(stages=encoders)\n",
    "    #df3 = pipeline2.transform(df2)\n",
    "\n",
    "    # Drop the original columns.\n",
    "    columns_to_drop = [\"Sex\", \"Civility\", \"Embarked\", \"Sex_index\", \"Civility_index\", \"Embarked_index\"]\n",
    "    df3 = df3.drop(*columns_to_drop)\n",
    "    \n",
    "    return df3\n",
    "    #return df3.toPandas()\n",
    "    #encoder = OneHotEncoder(inputCol=\"categoryIndex\", outputCol=\"categoryVec\")\n",
    "    #encoded = encoder.transform(indexed)\n",
    "    #encoded.show()\n",
    "    #raise NotImplementedError()\n",
    "result = one_hot_encode(extract_civility(data))\n",
    "resultCols = result.columns\n",
    "print(resultCols)\n",
    "print(len(resultCols))\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a1700e84915682868d08698e63761e2e",
     "grade": true,
     "grade_id": "cell-2ca43cb570eae17b",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "result = one_hot_encode(extract_civility(data))\n",
    "resultCols = result.columns\n",
    "assert len(resultCols) == 12\n",
    "\n",
    "assert 'SexVec' in resultCols\n",
    "assert 'CivilityVec' in resultCols\n",
    "assert 'EmbarkedVec' in resultCols\n",
    "\n",
    "assert 'Sex' not in resultCols\n",
    "assert 'Civility' not in resultCols\n",
    "assert 'Embarked' not in resultCols\n",
    "\n",
    "assert result.schema['SexVec'].simpleString() == 'SexVec:vector'\n",
    "assert result.schema['CivilityVec'].simpleString() == 'CivilityVec:vector'\n",
    "assert result.schema['EmbarkedVec'].simpleString() == 'EmbarkedVec:vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dab91b6c7834a91ffce574703c292c6a",
     "grade": false,
     "grade_id": "cell-eea586c0506e7fed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Question\n",
    "\n",
    "Now that we have created all of our numeric features, we need to assemble them into the same column. This is the goal of the [VectorAssembler](https://spark.apache.org/docs/2.2.0/ml-features.html#vectorassembler) transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5d779dc852a40f7ac15d24083cc86a5c",
     "grade": false,
     "grade_id": "cell-72faf34acdca3bb4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "def feature_assemble(df, featureCols):\n",
    "    \"\"\"\n",
    "    Assemble all features in the featureCols list into one column called 'features'.\n",
    "    \"\"\"\n",
    "    assembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\n",
    "    output = assembler.transform(df)\n",
    "    return output\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23b7efe52dcc5aeeac6114d27641f39c",
     "grade": true,
     "grade_id": "cell-7ad37566eead3ab5",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "2 points\n",
    "\"\"\"\n",
    "result = feature_assemble(data, ['Pclass', 'SibSp', 'Parch'])\n",
    "assert 'features' in result.columns\n",
    "assert result.schema['features'].simpleString() == 'features:vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c5df23e64ef240fbe5fb092a63cedf7",
     "grade": false,
     "grade_id": "cell-e0d94dd8381cf171",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### All the data preparation has been made. After running the following cell, we can concentrate on running ML modelling.\n",
    "\n",
    "For comparison purposes, let's try a Logistic Regression from MLlib and ML on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec8b4ddc9e87222209060ae5d0d05cdd",
     "grade": false,
     "grade_id": "cell-383133b054ab86e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: int, features: vector]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the data !\n",
    "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'SexVec', 'CivilityVec', 'EmbarkedVec']\n",
    "prepared_data = feature_assemble(one_hot_encode(extract_civility(replace_na(data))), features)\n",
    "prepared_data = prepared_data.withColumnRenamed(\"Survived\", \"label\").select(['label', 'features'])\n",
    "train, test = prepared_data.randomSplit([0.75, 0.25], 0)\n",
    "\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d6bb29333c6f86662eec9374a4ca529",
     "grade": false,
     "grade_id": "cell-e455c33086cadefb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## MLlib - RDD based API\n",
    "\n",
    "We will first use the RDD-based [Logistic Regression](https://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#logistic-regression). The exercise comes into two steps :\n",
    "\n",
    "1. First, you must create a RDD of LabeledPoint(label, features). Also careful as we are using `pyspark.ml.linalg.SparseVector` but the RDD-based API expects `pyspark.mllib.linalg.SparseVector`, so we need to [convert it](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=linearregressionwithsgd#pyspark.mllib.linalg.Vectors.fromML).\n",
    "2. Then you can apply LogisticRegression on it.\n",
    "\n",
    "# Question\n",
    "\n",
    "Train a logistic regression model on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ea1f00a84a090feaff75579223363b3",
     "grade": false,
     "grade_id": "cell-3d344e0fc760f3e0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def dataframe_to_labeledpoints(df):\n",
    "    \"\"\"\n",
    "    This function takes the conversion from a DataFrame of columns [label, features] to a RDD of LabeledPoint.    \n",
    "    \"\"\"\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    from pyspark.mllib.linalg import Vectors\n",
    "    \n",
    "    return df.rdd.map(lambda row: LabeledPoint(row[0], Vectors.fromML(row[1])))\n",
    "\n",
    "def train_mllib_logistic(train):\n",
    "    \"\"\"\n",
    "    Return a MLlib logistic regression trained on a RDD of LabeledPoint. \n",
    "    \"\"\"\n",
    "    # Build the model\n",
    "    model = LogisticRegressionWithLBFGS.train(train)\n",
    "\n",
    "    # Evaluating the model on training data\n",
    "    labelsAndPreds = train.map(lambda p: (p.label, model.predict(p.features)))\n",
    "    trainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(train.count())\n",
    "    print(\"Training Error = \" + str(trainErr))\n",
    "    return model\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a57929d658b4020e0f06871602d04b41",
     "grade": true,
     "grade_id": "cell-b54449b3f1087da2",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.1744186046511628\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "train_rdd = dataframe_to_labeledpoints(train)\n",
    "test_rdd = dataframe_to_labeledpoints(test)\n",
    "model = train_mllib_logistic(train_rdd)\n",
    "\n",
    "predictionAndLabels = test_rdd.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "assert metrics.areaUnderROC > 0.75  # I managed ~0.8 on my first try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6c51bd15ed342f964c8419cce9892b37",
     "grade": false,
     "grade_id": "cell-0967807fd54e6521",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## ML - DataFrame based API\n",
    "\n",
    "We now compare with using the ML [Logistic regression](https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#binomial-logistic-regression). It should work directly on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8261937d04d9a450c5251a2ee9eed67d",
     "grade": false,
     "grade_id": "cell-50cb55db71381eac",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "def train_ml_logistic(train):\n",
    "    \"\"\"\n",
    "    Return a MLlib logistic regression trained on a RDD of LabeledPoint. \n",
    "    \"\"\"\n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "    # Fit the model\n",
    "    lrModel = lr.fit(train)\n",
    "\n",
    "    # Print the coefficients and intercept for logistic regression\n",
    "    print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "    print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "    # We can also use the multinomial family for binary classification\n",
    "    mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "    # Fit the model\n",
    "    mlrModel = mlr.fit(train)\n",
    "\n",
    "    # Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "    print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "    print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))\n",
    "    return lrModel #mlrModel\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7def0348bf2f0ec5fa448f9093668879",
     "grade": true,
     "grade_id": "cell-2cb2116413925f78",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (24,[5,6],[-0.025454610373626316,-0.12952547089307428])\n",
      "Intercept: -0.40193996728772446\n",
      "Multinomial coefficients: 2 X 24 CSRMatrix\n",
      "(0,5) 0.0129\n",
      "(0,6) 0.0711\n",
      "(1,5) -0.0129\n",
      "(1,6) -0.0711\n",
      "Multinomial intercepts: [0.19674892392626103,-0.19674892392626103]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "3 points\n",
    "\"\"\"\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "model = train_ml_logistic(train)\n",
    "assert model.summary.areaUnderROC > 0.75 # managed 0.87 on my first try\n",
    "\n",
    "predictions = model.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "assert evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"}) > 0.75 # managed 0.88 on my first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ce916c26c6d960dbca976554f0a31bba",
     "grade": false,
     "grade_id": "cell-cc43fdd28fe66f9b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
